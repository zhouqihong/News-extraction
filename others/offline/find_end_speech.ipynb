{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# 导入上级目录，不然无法使父文件夹的代码\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyltp import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus_path = '../../word2vec/news_text/news_00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_news = open(news_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"2017年4月27日，在首尔光化门广场，民众在集会上手举反“萨德”标语。',\n",
       " '（新华社记者姚琪琳摄）新华社北京6月7日电（记者张旌）韩国国防部官员6日说，针对“萨德”在韩部署事宜，国防部方面已准备重新进行一场大规模的环境评估。',\n",
       " '完成新评估可能需要一年时间，“萨德”部署工作也将因此推迟或暂停。',\n",
       " '此前一天，青瓦台方面指责国防部试图把“萨德”对周围环境影响的评估过程“大事化小”，要求彻查此事。',\n",
       " '【环评“猫腻”遭曝光】韩国国防部官员6日向韩联社记者透露，青瓦台要求彻查“萨德”环境评估过程后，国防部已着手开展准备工作，将进行一场大规模的全面评估，预计可能耗时一年左右。',\n",
       " '根据这名官员的说法，国防部将就此事与青瓦台方面沟通后再制定详细方案，具体计划尚未确定。',\n",
       " '这名官员同时透露，目前，针对“萨德”用地的小规模环境评估正在进行中，预计将于本月底结束。',\n",
       " '此前一天，青瓦台方面表示，经调查发现，国防部在“萨德”环境评估过程中存在“猫腻”，试图“大事化小”，绕过相关法律规定。',\n",
       " '根据韩国相关法律，要在面积超过33万平方米的土地建新设施时，必须首先通过全面环境评估，以确定对周围环境影响的程度。',\n",
       " '韩国为美军提供的“萨德”部署地总面积约为70万平方米，按规定本应接受大规模环境评估。',\n",
       " '不过，根据青瓦台方面的说法，国防部把这块地分两批提供给美军，第一批面积为32万平方米，刚好避开全面环境评估的规定，只需接受小规模非正式评估。',\n",
       " '余下的部分稍晚些提供，也设法躲过了大规模环境评估。',\n",
       " '【部署进程或推迟】青瓦台方面发起这次调查，主要原因是要查明“另有4台发射架秘密运抵韩国”一事，而环境评估的“猫腻”正是在这一调查过程中被曝光。',\n",
       " '上月30日，青瓦台方面表示，总统文在寅获悉除目前已在韩部署的两台“萨德”系统移动发射架外，另有4台发射架已经秘密运抵韩国，感到“非常震惊”，要求彻查。',\n",
       " '青瓦台公报首席秘书尹永灿5日在记者会上说，调查已确认，瞒报事件主要责任人是国防部政策室长魏昇镐。',\n",
       " '由于魏昇镐已被停职，国防部还需重新确定一名指挥环境评估工作的负责人。',\n",
       " '青瓦台方面同时表示，将就此事展开进一步调查，以查明国防部长官韩民求和前总统朴槿惠时期的国家安保室长金宽镇是否与瞒报事件有关联。',\n",
       " '针对环评“猫腻”问题，青瓦台方面也将继续深挖，找出是谁想出“大事化小”的方法避开全面环境评估。',\n",
       " '目前韩国国内要求\"']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_line = next(f_news)\n",
    "\n",
    "sentencence = [s.replace('\\\\\\\\n','') for s in SentenceSplitter.split(news_line) if len(s.replace('\\\\\\\\n',''))>3]\n",
    "\n",
    "sentencence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 2.739 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "sen_cuted = [jieba.cut(sen)) for sen in sentencence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" 2017 年 5 月 29 日 ， 在 法国巴黎 郊外 的 凡尔赛宫 ， 法国 总统 马克 龙 出席 新闻 发布会 。',\n",
       " '（ 新华 / 法新 ） 新华社 北京 6 月 7 日电 （ 记者 张 旌 ） 法国 定于 6 月 11 日 举行 议会选举 首轮 投票 。',\n",
       " '最新 民调 结果显示 ， 总统 埃马 纽埃 尔 · 马克 龙 领导 的 “ 共和国 前进 ” 运动 将 在 这场 选举 中 获得 “ 压倒性 胜利 ” ， 不仅 将 赢得 议会 多数 席位 ， 数量 还 可望 创下 1968 年 以来 历届 执政党 的 最高值 。',\n",
       " '对 马克 龙 而言 ， 要 坐 稳 总统 宝座 ， 赢得 这场 选举 至关重要 。',\n",
       " '法国议会 选举 有着 “ 第三轮 选举 ” 之称 ， 将 决定 议会 多数派 归属 ， 影响 法国政府 未来 五年 的 实际 执政 方向 。',\n",
       " '民调 机构 益普索 集团 6 日 公布 的 最新 民调 结果显示 ， 在 本月 11 日 举行 的 议会选举 首轮 投票 中 ， 马克 龙 领导 的 “ 共和国 前进 ” 运动 得票率 将 可达 29.5% 。',\n",
       " '相比之下 ， 共和党 阵营 得票率 预计 为 23% ， 极右翼 “ 国民 阵线 ” 得票率 预计 为 17% ， 极 左翼 政治势力 “ 不屈 法国 ” 得票率 预计 为 12.5% ， 而 社会党 有望 获得 8.5% 的 选票 。',\n",
       " '这项 民调 同时 显示 ， 在 定于 6 月 18 日 举行 的 议会选举 第二轮 投票 中 ， “ 共和国 前进 ” 运动 将 获得 议会下院 577 个 议席 中 的 385 至 415 个 议席 。',\n",
       " '在 一周 前 进行 的 另 一场 类似 民调 中 ， “ 共和国 前进 ” 运动 预计 得票率 曾 高达 31% 。',\n",
       " '新政府 两名 部长 被 曝 牵涉 “ 空饷 门 ” 后 ， “ 共和国 前进 ” 运动 的 支持率 似乎 有 下跌 之势 。',\n",
       " '不过 ， 民调 结果显示 ， “ 空饷 门 ” 事件 并未 影响 马克 龙 在 民众 心目 中 的 形象 。',\n",
       " '约 60% 的 受访者 表示 ， 他们 对 马克 龙 的 表现 感到 满意 。',\n",
       " '“ 共和国 前进 ” 运动 去年 6 月 成立 ， 眼下 在 议会 并 无 席位 。',\n",
       " '此前 曾 有人 担忧 ， 如果 “ 共和国 前进 ” 运动 不能 在 议会选举 中 赢得 多数 席位 ， 马克 龙 届时 将 被迫 组建 联合政府 ， 甚至 沦为 “ 名义 上 的 总统 ” 。']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_cuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11', '12', '17', '18', '1968', '2017', '23', '29', '31', '385', '415', '577', '60', '一周', '一场', '下跌', '不仅', '不屈', '不能', '不过', '两名', '举行', '之势', '之称', '事件', '五年', '他们', '以来', '似乎', '公布', '共和党', '共和国', '决定', '凡尔赛宫', '出席', '创下', '前进', '北京', '历届', '压倒性', '去年', '发布会', '受访者', '可望', '可达', '同时', '名义', '国民', '埃马', '多数', '多数派', '如果', '定于', '宝座', '实际', '届时', '左翼', '席位', '并未', '归属', '形象', '影响', '得票率', '心目', '总统', '感到', '成立', '执政', '执政党', '投票', '担忧', '支持率', '政治势力', '数量', '新华', '新华社', '新政府', '新闻', '方向', '日电', '显示', '最新', '最高值', '有人', '有望', '有着', '未来', '本月', '机构', '极右翼', '此前', '民众', '民调', '沦为', '法国', '法国巴黎', '法国政府', '法国议会', '法新', '满意', '牵涉', '甚至', '益普索', '相比之下', '眼下', '社会党', '空饷', '第三轮', '第二轮', '类似', '纽埃', '组建', '结果显示', '而言', '联合政府', '胜利', '至关重要', '获得', '表现', '表示', '被迫', '议会', '议会下院', '议会选举', '议席', '记者', '赢得', '运动', '这场', '这项', '进行', '选举', '选票', '郊外', '部长', '阵线', '阵营', '集团', '预计', '领导', '首轮', '马克', '高达']\n",
      "[[0 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
    ">>> corpus = [\n",
    "...     'This is the first document.',\n",
    "...     'This document is the second document.',\n",
    "...     'And this is the third one.',\n",
    "...     'Is this the first document?',\n",
    "... ]\n",
    ">>> vectorizer = CountVectorizer()\n",
    ">>> X = vectorizer.fit_transform(sen_cuted)\n",
    ">>> print(vectorizer.get_feature_names())\n",
    "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
    ">>> print(X.toarray())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 143)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5,   7,  33,  34,  41,  64,  77,  94,  95, 133, 141]),)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(X[0].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017', '29', '凡尔赛宫', '出席', '发布会', '总统', '新闻', '法国', '法国巴黎', '郊外', '马克']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fns[i] for i in np.where(X[0].toarray()[0])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 27, 48, 16, 24, 37, 39, 37, 22, 24, 21, 15, 17, 36]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i.split()) for i in sen_cuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x13 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> corpus = [\n",
    "...     'This is the first document.',\n",
    "...     'This is the second second document.',\n",
    "...     'And the third one.',\n",
    "...     'Is  a is this the first document? ',\n",
    "... ]\n",
    ">>> X = vectorizer.fit_transform(corpus)\n",
    ">>> X                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'text', 'document', 'to', 'analyze']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(\"This is a text document to analyze. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'is': 3,\n",
       " 'one': 4,\n",
       " 'second': 5,\n",
       " 'the': 6,\n",
       " 'third': 7,\n",
       " 'this': 8}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 2, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> xa = np.array([[3, 0, 1],\n",
    "...           [2, 0, 0],\n",
    "...           [3, 0, 0],\n",
    "...           [4, 0, 0],\n",
    "...           [3, 2, 0],\n",
    "...           [3, 0, 2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = xa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = xa.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.sum(xa!=0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 3, 1, 1, 4, 1, 3])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log((n+1)/(df+1))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.22314355, 1.51082562, 1.22314355, 1.91629073,\n",
       "       1.91629073, 1.        , 1.91629073, 1.22314355])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.22314355, 1.51082562, 1.22314355, 0.        ,\n",
       "       0.        , 1.        , 0.        , 1.22314355])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf*idf\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_sum = np.sqrt(np.sum(np.square(tf_idf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
       "       0.        , 0.35872874, 0.        , 0.43877674])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf/norm_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.feature_extraction.text import TfidfTransformer\n",
    ">>> transformer = TfidfTransformer()\n",
    ">>> transformer   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_com = transformer.fit_transform(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
       "        0.        , 0.35872874, 0.        , 0.43877674],\n",
       "       [0.        , 0.27230147, 0.        , 0.27230147, 0.        ,\n",
       "        0.85322574, 0.22262429, 0.        , 0.27230147],\n",
       "       [0.55280532, 0.        , 0.        , 0.        , 0.55280532,\n",
       "        0.        , 0.28847675, 0.55280532, 0.        ],\n",
       "       [0.        , 0.34934021, 0.43150466, 0.69868042, 0.        ,\n",
       "        0.        , 0.28560851, 0.        , 0.34934021]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_com.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "S= 888 if S > 10 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(i for i in range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_tes(x):\n",
    "    print(x)\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ../../word2vec/stopwords/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pre = '../../word2vec/stopwords/'\n",
    "for i in os.listdir(pre):\n",
    "    with open(pre+i) as f:\n",
    "        STOPWORD += [i for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD =set(STOPWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD = list(STOPWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt','w') as f:\n",
    "    f.writelines(STOPWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'不过' in STOPWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> vectorizer = TfidfVectorizer(analyzer=lambda x:[i for i in jieba.cut(x) if i not in STOPWORD])\n",
    ">>> tfidf_X = vectorizer.fit_transform(sentencence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13091852, 0.13091852, 0.09109838, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.25104596, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22611726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.25104596, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28618098, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28618098, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.17762452, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.22611726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25104596, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.25104596, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.28618098, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.28618098,\n",
       "       0.        , 0.        , 0.        , 0.28618098, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.14671735, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11756081, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.19098224, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.28618098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09109838])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X.toarray()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'（ 新华 / 法新 ） 新华社 北京 6 月 7 日电 （ 记者 张 旌 ） 法国 定于 6 月 11 日 举行 议会选举 首轮 投票 。'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_cuted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2017年4月27日，在首尔光化门广场，民众在集会上手举反“萨德”标语。\n",
      "0.11852061057535798\n",
      "（新华社记者姚琪琳摄）新华社北京6月7日电（记者张旌）韩国国防部官员6日说，针对“萨德”在韩部署事宜，国防部方面已准备重新进行一场大规模的环境评估。\n",
      "0.07453308396641231\n",
      "完成新评估可能需要一年时间，“萨德”部署工作也将因此推迟或暂停。\n",
      "0.12500111618653492\n",
      "此前一天，青瓦台方面指责国防部试图把“萨德”对周围环境影响的评估过程“大事化小”，要求彻查此事。\n",
      "0.29118161606245435\n",
      "【环评“猫腻”遭曝光】韩国国防部官员6日向韩联社记者透露，青瓦台要求彻查“萨德”环境评估过程后，国防部已着手开展准备工作，将进行一场大规模的全面评估，预计可能耗时一年左右。\n",
      "0.151658319177144\n",
      "根据这名官员的说法，国防部将就此事与青瓦台方面沟通后再制定详细方案，具体计划尚未确定。\n",
      "0.16635768013524146\n",
      "这名官员同时透露，目前，针对“萨德”用地的小规模环境评估正在进行中，预计将于本月底结束。\n",
      "0.24143639808408046\n",
      "此前一天，青瓦台方面表示，经调查发现，国防部在“萨德”环境评估过程中存在“猫腻”，试图“大事化小”，绕过相关法律规定。\n",
      "0.1860692907303759\n",
      "根据韩国相关法律，要在面积超过33万平方米的土地建新设施时，必须首先通过全面环境评估，以确定对周围环境影响的程度。\n",
      "0.12183871696239967\n",
      "韩国为美军提供的“萨德”部署地总面积约为70万平方米，按规定本应接受大规模环境评估。\n",
      "0.3018062589912216\n",
      "不过，根据青瓦台方面的说法，国防部把这块地分两批提供给美军，第一批面积为32万平方米，刚好避开全面环境评估的规定，只需接受小规模非正式评估。\n",
      "0.13511617444466273\n",
      "余下的部分稍晚些提供，也设法躲过了大规模环境评估。\n",
      "0.05101490717433696\n",
      "--------------------------------------------\n",
      "【部署进程或推迟】青瓦台方面发起这次调查，主要原因是要查明“另有4台发射架秘密运抵韩国”一事，而环境评估的“猫腻”正是在这一调查过程中被曝光。\n",
      "0.3327022043243049\n",
      "上月30日，青瓦台方面表示，总统文在寅获悉除目前已在韩部署的两台“萨德”系统移动发射架外，另有4台发射架已经秘密运抵韩国，感到“非常震惊”，要求彻查。\n",
      "0.13834189238224318\n",
      "青瓦台公报首席秘书尹永灿5日在记者会上说，调查已确认，瞒报事件主要责任人是国防部政策室长魏昇镐。\n",
      "0.20844455671381013\n",
      "由于魏昇镐已被停职，国防部还需重新确定一名指挥环境评估工作的负责人。\n",
      "0.024374471332452054\n",
      "--------------------------------------------\n",
      "青瓦台方面同时表示，将就此事展开进一步调查，以查明国防部长官韩民求和前总统朴槿惠时期的国家安保室长金宽镇是否与瞒报事件有关联。\n",
      "0.07366816297597856\n",
      "针对环评“猫腻”问题，青瓦台方面也将继续深挖，找出是谁想出“大事化小”的方法避开全面环境评估。\n",
      "0.0\n",
      "--------------------------------------------\n",
      "目前韩国国内要求\"\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(sentencence)-1):\n",
    "    print(sentencence[index])\n",
    "    simi = cosine_similarity(tfidf_X[index],tfidf_X[index+1])\n",
    "    print(simi[0][0])\n",
    "    if simi[0][0] <0.06:\n",
    "        print('--------------------------------------------')\n",
    "print(sentencence[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = STOPWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "# from utils.load_data import load_stopwords\n",
    "# STOPWORDS = load_stopwords()\n",
    "class TfidfDecisimMaker:\n",
    "    \"\"\"\n",
    "    将句子使用TFIDF向量化表示，判断相邻两句的cosine 相似度。相似度小于某一阈值，认为相邻的两句不相关。可以断句\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,segmented_sentences, alpha=0.1, max_length=3):\n",
    "        self.sentences = segmented_sentences\n",
    "        self.alpha = alpha\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.vectorizer = TfidfVectorizer(analyzer=self.clean_words)\n",
    "        #print(self.sentences)\n",
    "        self.tfidf_X = self.vectorizer.fit_transform(self.sentences)\n",
    "        self.doc_length = len(segmented_sentences)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def clean_words(sen):\n",
    "#         print(sen)\n",
    "        return [s for s in sen if s not in STOPWORDS]\n",
    "\n",
    "    def get_end_index(self,sen_index):\n",
    "        base_vector = self.tfidf_X[sen_index]\n",
    "        end_index = sen_index\n",
    "        print(''.join(self.sentences[sen_index]))\n",
    "        for i in range(sen_index+1,sen_index+self.max_length+1):\n",
    "            similarity = cosine_similarity(base_vector, self.tfidf_X[i])\n",
    "            if similarity[0][0] > self.alpha:\n",
    "                print(similarity[0][0],''.join(self.sentences[i]))\n",
    "                end_index = i\n",
    "            else:\n",
    "                break\n",
    "        return end_index \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这名官员同时透露，目前，针对“萨德”用地的小规模环境评估正在进行中，预计将于本月底结束。\n",
      "0.24143639808408046 此前一天，青瓦台方面表示，经调查发现，国防部在“萨德”环境评估过程中存在“猫腻”，试图“大事化小”，绕过相关法律规定。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuted = [jieba.lcut(sen) for sen in sentencence if sen]\n",
    "\n",
    "tfmaker = TfidfDecisimMaker(cuted,alpha=0.2,max_length=3)\n",
    "\n",
    "tfmaker.get_end_index(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"2017年4月27日，在首尔光化门广场，民众在集会上手举反“萨德”标语。',\n",
       " '（新华社记者姚琪琳摄）新华社北京6月7日电（记者张旌）韩国国防部官员6日说，针对“萨德”在韩部署事宜，国防部方面已准备重新进行一场大规模的环境评估。',\n",
       " '完成新评估可能需要一年时间，“萨德”部署工作也将因此推迟或暂停。',\n",
       " '此前一天，青瓦台方面指责国防部试图把“萨德”对周围环境影响的评估过程“大事化小”，要求彻查此事。',\n",
       " '【环评“猫腻”遭曝光】韩国国防部官员6日向韩联社记者透露，青瓦台要求彻查“萨德”环境评估过程后，国防部已着手开展准备工作，将进行一场大规模的全面评估，预计可能耗时一年左右。',\n",
       " '根据这名官员的说法，国防部将就此事与青瓦台方面沟通后再制定详细方案，具体计划尚未确定。',\n",
       " '这名官员同时透露，目前，针对“萨德”用地的小规模环境评估正在进行中，预计将于本月底结束。',\n",
       " '此前一天，青瓦台方面表示，经调查发现，国防部在“萨德”环境评估过程中存在“猫腻”，试图“大事化小”，绕过相关法律规定。',\n",
       " '根据韩国相关法律，要在面积超过33万平方米的土地建新设施时，必须首先通过全面环境评估，以确定对周围环境影响的程度。',\n",
       " '韩国为美军提供的“萨德”部署地总面积约为70万平方米，按规定本应接受大规模环境评估。',\n",
       " '不过，根据青瓦台方面的说法，国防部把这块地分两批提供给美军，第一批面积为32万平方米，刚好避开全面环境评估的规定，只需接受小规模非正式评估。',\n",
       " '余下的部分稍晚些提供，也设法躲过了大规模环境评估。',\n",
       " '【部署进程或推迟】青瓦台方面发起这次调查，主要原因是要查明“另有4台发射架秘密运抵韩国”一事，而环境评估的“猫腻”正是在这一调查过程中被曝光。',\n",
       " '上月30日，青瓦台方面表示，总统文在寅获悉除目前已在韩部署的两台“萨德”系统移动发射架外，另有4台发射架已经秘密运抵韩国，感到“非常震惊”，要求彻查。',\n",
       " '青瓦台公报首席秘书尹永灿5日在记者会上说，调查已确认，瞒报事件主要责任人是国防部政策室长魏昇镐。',\n",
       " '由于魏昇镐已被停职，国防部还需重新确定一名指挥环境评估工作的负责人。',\n",
       " '青瓦台方面同时表示，将就此事展开进一步调查，以查明国防部长官韩民求和前总统朴槿惠时期的国家安保室长金宽镇是否与瞒报事件有关联。',\n",
       " '针对环评“猫腻”问题，青瓦台方面也将继续深挖，找出是谁想出“大事化小”的方法避开全面环境评估。',\n",
       " '目前韩国国内要求\"']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm([1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2,3],[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([1,1],[2,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
